{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f0b883-4358-483a-85da-65bab560b5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tf.__version__\n",
    "\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "423e9b7c-ce4b-4708-941f-2a04a8649e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn import *\n",
    "from CAAE import CAAE\n",
    "from utils import read_tfrecord, data_from_tfrecord, data_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e983933-7ace-43bf-b1c3-bb8b6b826d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data info:  {'train_unlabel': 336362, 'train_label': 37372, 'validation': 80084, 'test': 80084}\n",
      "Num labeled normal:  24693\n",
      "Num labeled attack:  12679\n"
     ]
    }
   ],
   "source": [
    "data_info = {\n",
    "   \"train_unlabel\": 0, \n",
    "    \"train_label\": 0, \n",
    "    \"validation\": 0, \n",
    "    \"test\": 0\n",
    "}\n",
    "labels = ['DoS', 'Fuzzy', 'gear', 'RPM', 'Normal']\n",
    "unknown_attack = 'DoS'\n",
    "num_normal = 0\n",
    "num_attack = 0\n",
    "for f in ['./Data/{}/datainfo.txt'.format(l) for l in labels if l is not unknown_attack]:\n",
    "    data_read = json.load(open(f))\n",
    "    for key in data_info.keys():\n",
    "        data_info[key] += data_read[key]\n",
    "    if 'Normal' in f:\n",
    "        num_normal += data_read['train_label']\n",
    "    else:\n",
    "        num_attack += data_read['train_label']\n",
    "        \n",
    "attack = 'all' # DoS, Fuzzy, gear, RPM, all\n",
    "if unknown_attack != '':\n",
    "    results_path = './Results/unknown/{}'.format(unknown_attack)\n",
    "else:\n",
    "    results_path = './Results/{}/'.format(attack)\n",
    "print('Data info: ', data_info)\n",
    "print('Num labeled normal: ', num_normal)\n",
    "print('Num labeled attack: ', num_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493c1a59-fd01-4357-bea4-94c7db0baa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown attack:  DoS\n",
      "Data info:  {'train_unlabel': 23594, 'train_label': 2621, 'validation': 5617, 'test': 5617}\n",
      "Train unlabel size: 2359\n"
     ]
    }
   ],
   "source": [
    "print('Unknown attack: ', unknown_attack)\n",
    "data_info_unknown_attack = json.load(open('./Data/{}/datainfo.txt'.format(unknown_attack)))\n",
    "val_unknown_path = ['./Data/{}/val'.format(unknown_attack)]\n",
    "train_unlabel_unknown_attack_path = './Data/{}/train_unlabel'.format(unknown_attack)\n",
    "print('Data info: ', data_info_unknown_attack)\n",
    "train_unlabel_unknown_size = int(data_info_unknown_attack['train_unlabel'] * 0.1)\n",
    "validation_unknown_size = data_info_unknown_attack['validation']\n",
    "print('Train unlabel size:', train_unlabel_unknown_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e568e06-2d3c-4271-afb5-6f626f119df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_dim = 29 * 29\n",
    "n_l1 = 1000\n",
    "n_l2 = 1000\n",
    "z_dim = 10\n",
    "batch_size_unknown = 5\n",
    "batch_size = 64\n",
    "n_epochs = 500\n",
    "# learning_rate = 0.001\n",
    "supervised_lr = 0.0001\n",
    "reconstruction_lr = 0.0001\n",
    "regularization_lr = 0.0001\n",
    "beta1 = 0.9\n",
    "n_labels = 2\n",
    "n_labeled = data_info['train_label']\n",
    "validation_size = data_info['validation']\n",
    "\n",
    "model = CAAE(n_labels = n_labels, z_dim = z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "790e4f93-9715-4d2e-a879-92493fef2985",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thiennu/Research/IDS/utils.py:22: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "Train unlabel:  ['./Data/Fuzzy/train_unlabel', './Data/gear/train_unlabel', './Data/RPM/train_unlabel', './Data/Normal/train_unlabel']\n",
      "Train label:  ['./Data/Fuzzy/train_label', './Data/gear/train_label', './Data/RPM/train_label', './Data/Normal/train_label']\n",
      "Validation:  ['./Data/Fuzzy/val', './Data/gear/val', './Data/RPM/val', './Data/Normal/val']\n"
     ]
    }
   ],
   "source": [
    "train_unlabel_paths = ['./Data/{}/train_unlabel'.format(l) for l in labels if l is not unknown_attack]\n",
    "unknown_train_unlabel_path = ['./Data/{}/train_unlabel'.format(unknown_attack)]\n",
    "train_label_paths = ['./Data/{}/train_label'.format(l) for l in labels if l is not unknown_attack]\n",
    "val_paths = ['./Data/{}/val'.format(l) for l in labels if l is not unknown_attack]\n",
    "\n",
    "train_unlabel = data_from_tfrecord(train_unlabel_paths, batch_size - batch_size_unknown, n_epochs)\n",
    "train_label = data_from_tfrecord(train_label_paths, batch_size, n_epochs)\n",
    "validation = data_from_tfrecord(val_paths, batch_size, n_epochs)\n",
    "if unknown_attack != '':\n",
    "    validation_unknown = data_from_tfrecord(val_unknown_path, batch_size, n_epochs)\n",
    "    train_unlabel_unknown = data_from_tfrecord(unknown_train_unlabel_path, batch_size_unknown, n_epochs)\n",
    "\n",
    "print('Train unlabel: ', train_unlabel_paths)\n",
    "print('Train label: ', train_label_paths)\n",
    "print('Validation: ', val_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5b4cca5-fab9-486b-af10-bc84ebbbd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = tf.placeholder(dtype=tf.float32, shape=[batch_size, input_dim], name='Input')\n",
    "x_input_l = tf.placeholder(dtype=tf.float32, shape=[batch_size, input_dim], name='Labeled_Input')\n",
    "y_input = tf.placeholder(dtype=tf.float32, shape=[batch_size, n_labels], name='Labels')\n",
    "x_target = tf.placeholder(dtype=tf.float32, shape=[batch_size, input_dim], name='Target')\n",
    "real_distribution = tf.placeholder(dtype=tf.float32, shape=[batch_size, z_dim], name='Real_distribution')\n",
    "categorial_distribution = tf.placeholder(dtype=tf.float32, shape=[batch_size, n_labels],\n",
    "                                         name='Categorical_distribution')\n",
    "manual_decoder_input = tf.placeholder(dtype=tf.float32, shape=[1, z_dim + n_labels], name='Decoder_input')\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9827cda0-8269-489e-8300-4125f1656038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thiennu/Research/IDS/cnn.py:8: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/thiennu/Research/IDS/cnn.py:33: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/thiennu/Research/IDS/cnn.py:61: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "(64, 2) (64, 10)\n",
      "WARNING:tensorflow:From /home/thiennu/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1417: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/thiennu/Research/IDS/cnn.py:42: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reconstruction Phase\n",
    "# Encoder try to predict both label and latent space of the input, which will be feed into Decoder to reconstruct the input\n",
    "# The process is optimized by autoencoder_loss which is the MSE of the decoder_output and the orginal input\n",
    "with (tf.variable_scope(tf.get_variable_scope())):\n",
    "    encoder_output_label, encoder_output_latent = model.encoder(x_input)\n",
    "    print(encoder_output_label.shape, encoder_output_latent.shape)\n",
    "    decoder_input = tf.concat([encoder_output_label, encoder_output_latent], 1)\n",
    "    decoder_output = model.decoder(decoder_input)\n",
    "\n",
    "autoencoder_loss = tf.reduce_mean(tf.square(x_target - decoder_output))\n",
    "autoencoder_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(autoencoder_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4660e7f5-d4cb-402e-a2fd-ae4d0bb49d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thiennu/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Decoder gaussian variable:  [<tf.Variable 'dc_g_den1/weights:0' shape=(10, 1000) dtype=float32_ref>, <tf.Variable 'dc_g_den1/bias:0' shape=(1000,) dtype=float32_ref>, <tf.Variable 'dc_g_den2/weights:0' shape=(1000, 1000) dtype=float32_ref>, <tf.Variable 'dc_g_den2/bias:0' shape=(1000,) dtype=float32_ref>, <tf.Variable 'dc_g_output/weights:0' shape=(1000, 1) dtype=float32_ref>, <tf.Variable 'dc_g_output/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "Decoder categorical variable:  [<tf.Variable 'dc_c_den1/weights:0' shape=(2, 1000) dtype=float32_ref>, <tf.Variable 'dc_c_den1/bias:0' shape=(1000,) dtype=float32_ref>, <tf.Variable 'dc_c_den2/weights:0' shape=(1000, 1000) dtype=float32_ref>, <tf.Variable 'dc_c_den2/bias:0' shape=(1000,) dtype=float32_ref>, <tf.Variable 'dc_c_output/weights:0' shape=(1000, 1) dtype=float32_ref>, <tf.Variable 'dc_c_output/bias:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "# Regularization Phase\n",
    "# Train both 2 discriminator of gaussian and categorical to detect the output from encoder\n",
    "with (tf.variable_scope(tf.get_variable_scope())):\n",
    "    # Discriminator for gaussian\n",
    "    d_g_real = model.discriminator_gauss(real_distribution)\n",
    "    d_g_fake = model.discriminator_gauss(encoder_output_latent, reuse=True)\n",
    "# Need to seperate dicriminator of gaussian and categorical\n",
    "with (tf.variable_scope(tf.get_variable_scope())):\n",
    "    # Discrimnator for categorical\n",
    "    d_c_real = model.discriminator_categorical(categorial_distribution)\n",
    "    d_c_fake = model.discriminator_categorical(encoder_output_label, reuse=True)\n",
    "\n",
    "# Discriminator gaussian loss \n",
    "dc_g_loss_real = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_g_real), logits=d_g_real))\n",
    "dc_g_loss_fake = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(d_g_fake), logits=d_g_fake))\n",
    "dc_g_loss = dc_g_loss_real + dc_g_loss_fake\n",
    "\n",
    "# Discriminator categorical loss\n",
    "dc_c_loss_real = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_c_real), logits=d_c_real))\n",
    "dc_c_loss_fake = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(d_c_fake), logits=d_c_fake))\n",
    "dc_c_loss = dc_c_loss_fake + dc_c_loss_real\n",
    "\n",
    "all_variables = tf.trainable_variables()\n",
    "dc_g_var = [var for var in all_variables if 'dc_g_' in var.name]\n",
    "dc_c_var = [var for var in all_variables if 'dc_c_' in var.name]\n",
    "\n",
    "print('Decoder gaussian variable: ', dc_g_var)\n",
    "print('Decoder categorical variable: ', dc_c_var)\n",
    "\n",
    "discriminator_g_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n",
    "                                                       beta1=beta1).minimize(dc_g_loss, var_list=dc_g_var)\n",
    "discriminator_c_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n",
    "                                                       beta1=beta1).minimize(dc_c_loss, var_list=dc_c_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323b0d99-de56-40ff-bc5f-2ddea83c4c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder variable:  [<tf.Variable 'e_conv1/w_e_conv1:0' shape=(3, 3, 1, 32) dtype=float32_ref>, <tf.Variable 'e_conv1/b_e_conv1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'e_conv2/w_e_conv2:0' shape=(3, 3, 32, 32) dtype=float32_ref>, <tf.Variable 'e_conv2/b_e_conv2:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'e_conv3/w_e_conv3:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'e_conv3/b_e_conv3:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'e_conv4/w_e_conv4:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'e_conv4/b_e_conv4:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'e_latent_variable/w_e_latent_variable:0' shape=(256, 10) dtype=float32_ref>, <tf.Variable 'e_latent_variable/b_e_latent_variable:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'e_label/w_e_label:0' shape=(256, 2) dtype=float32_ref>, <tf.Variable 'e_label/b_e_label:0' shape=(2,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "# Generator loss\n",
    "generator_g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_g_fake), logits=d_g_fake))\n",
    "generator_c_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_c_fake), logits=d_c_fake))\n",
    "generator_loss = generator_g_loss + generator_c_loss\n",
    "\n",
    "en_var = [var for var in all_variables if 'e_' in var.name]\n",
    "print('Encoder variable: ', en_var)\n",
    "generator_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(generator_loss, var_list=en_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94db4f40-b30b-49b2-89b1-8be483d57f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-ec3b1fd09a56>:11: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Semi-Supervised Classification Phase\n",
    "# Train encoder with a small amount of label samples\n",
    "with tf.variable_scope(tf.get_variable_scope()):\n",
    "    encoder_output_label_, encoder_output_latent = model.encoder(x_input_l, reuse=True, supervised=True)\n",
    "    \n",
    "# Classification accuracy of encoder\n",
    "output_label = tf.argmax(encoder_output_label_, 1)\n",
    "correct_pred = tf.equal(output_label, tf.argmax(y_input, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "supervised_encoder_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_input, logits=encoder_output_label_))\n",
    "supervised_encoder_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(supervised_encoder_loss, var_list=en_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01693af6-89a3-48b4-9980-2bee1d3ee97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_results():\n",
    "    \"\"\"\n",
    "    Forms folders for each run to store the tensorboard files, saved models and the log files.\n",
    "    :return: three string pointing to tensorboard, saved models and log paths respectively.\n",
    "    \"\"\"\n",
    "    folder_name = \"/CNN_{0}_{1}_{2}_{3}_{4}_{5}_Semi_Supervised\". \\\n",
    "        format(datetime.datetime.now(), z_dim, supervised_lr, batch_size, n_epochs, beta1)\n",
    "    tensorboard_path = results_path + folder_name + '/Tensorboard'\n",
    "    saved_model_path = results_path + folder_name + '/Saved_models/'\n",
    "    log_path = results_path + folder_name + '/log'\n",
    "    if not os.path.exists(results_path + folder_name):\n",
    "        os.mkdir(results_path + folder_name)\n",
    "        os.mkdir(tensorboard_path)\n",
    "        os.mkdir(saved_model_path)\n",
    "        os.mkdir(log_path)\n",
    "    return tensorboard_path, saved_model_path, log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca62eb2d-d0a2-4905-b118-5eba4c67507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_acc(val_size, batch_size, tfdata):\n",
    "    acc = 0\n",
    "    y_true, y_pred = [], []\n",
    "    num_batches = int(val_size/batch_size)\n",
    "    for j in tqdm.tqdm(range(num_batches)):\n",
    "        batch_x_l, batch_y_l = data_stream(tfdata, sess)\n",
    "        batch_pred = sess.run(output_label, feed_dict={x_input_l: batch_x_l, y_input: batch_y_l})\n",
    "        \n",
    "        #batch_pred = sess.run(pred_label, feed_dict={x_input_l: x_test})\n",
    "        batch_label = np.argmax(batch_y_l, axis=1)\n",
    "        y_pred += batch_pred.tolist()\n",
    "        y_true += batch_label.tolist()\n",
    "        \n",
    "    avg_acc = np.equal(y_true, y_pred).mean()\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    fnr = fn/(tp + fn)\n",
    "    err = (fn + fp) / (tp + tn + fp + fn)\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = 1 - fnr\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "    #print(avg_acc, precision, recall, f1)\n",
    "    return avg_acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13d72bba-e5b6-4539-a2a9-9040b40c9d99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Autoencoder Loss is illegal; using Autoencoder_Loss instead.\n",
      "INFO:tensorflow:Summary name Discriminator gauss Loss is illegal; using Discriminator_gauss_Loss instead.\n",
      "INFO:tensorflow:Summary name Discriminator categorical Loss is illegal; using Discriminator_categorical_Loss instead.\n",
      "INFO:tensorflow:Summary name Generator Loss is illegal; using Generator_Loss instead.\n",
      "INFO:tensorflow:Summary name Supervised Encoder Loss is illegal; using Supervised_Encoder_Loss instead.\n",
      "INFO:tensorflow:Summary name Encoder Gauss Distribution is illegal; using Encoder_Gauss_Distribution instead.\n",
      "INFO:tensorflow:Summary name Real Gauss Distribution is illegal; using Real_Gauss_Distribution instead.\n",
      "INFO:tensorflow:Summary name Encoder Categorical Distribution is illegal; using Encoder_Categorical_Distribution instead.\n",
      "INFO:tensorflow:Summary name Real Categorical Distribution is illegal; using Real_Categorical_Distribution instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Epoch 0/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:14<00:00, 41.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24655\n",
      "Num attack:  12657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/583 [00:00<00:11, 51.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Epoch 1/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.38it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24656\n",
      "Num attack:  12656\n",
      "------------------Epoch 2/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 48.07it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24644\n",
      "Num attack:  12668\n",
      "------------------Epoch 3/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.83it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24661\n",
      "Num attack:  12651\n",
      "------------------Epoch 4/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 45.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24646\n",
      "Num attack:  12666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/583 [00:00<00:15, 37.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Epoch 5/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 45.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24669\n",
      "Num attack:  12643\n",
      "WARNING:tensorflow:From /home/thiennu/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Epoch 6/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 46.90it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24632\n",
      "Num attack:  12680\n",
      "------------------Epoch 7/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 45.24it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24688\n",
      "Num attack:  12624\n",
      "------------------Epoch 8/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 48.53it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24634\n",
      "Num attack:  12678\n",
      "------------------Epoch 9/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 47.79it/s]\n",
      "  0%|          | 0/1251 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24669\n",
      "Num attack:  12643\n",
      "Runing on validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [00:02<00:00, 498.60it/s]\n",
      " 24%|██▍       | 21/87 [00:00<00:00, 208.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Known attack: 0.9539868105515588\n",
      "Precision on Known attack: 0.9680995294680597\n",
      "Recall on Known attack: 0.8938222516751344\n",
      "F1 on Known attack: 0.92947932618683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 407.22it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on unKnown attack: 0.00017959770114942528\n",
      "Precision on unKnown attack: 1.0\n",
      "Recall on unKnown attack: 0.0001795977011493921\n",
      "F1 on unKnown attack: 0.00035913090321415525\n",
      "------------------Epoch 10/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.00it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24633\n",
      "Num attack:  12679\n",
      "------------------Epoch 11/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 48.66it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24659\n",
      "Num attack:  12653\n",
      "------------------Epoch 12/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.84it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24638\n",
      "Num attack:  12674\n",
      "------------------Epoch 13/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 47.25it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24668\n",
      "Num attack:  12644\n",
      "------------------Epoch 14/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 47.66it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24662\n",
      "Num attack:  12650\n",
      "------------------Epoch 15/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 48.97it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24615\n",
      "Num attack:  12697\n",
      "------------------Epoch 16/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.16it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24677\n",
      "Num attack:  12635\n",
      "------------------Epoch 17/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.20it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24655\n",
      "Num attack:  12657\n",
      "------------------Epoch 18/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 48.64it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24660\n",
      "Num attack:  12652\n",
      "------------------Epoch 19/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 48.38it/s]\n",
      "  4%|▍         | 55/1251 [00:00<00:02, 549.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24658\n",
      "Num attack:  12654\n",
      "Runing on validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [00:02<00:00, 564.54it/s]\n",
      "100%|██████████| 87/87 [00:00<00:00, 572.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Known attack: 0.984375\n",
      "Precision on Known attack: 0.9903092705454821\n",
      "Recall on Known attack: 0.9633598468110178\n",
      "F1 on Known attack: 0.9766486849719075\n",
      "Accuracy on unKnown attack: 0.00017959770114942528\n",
      "Precision on unKnown attack: 1.0\n",
      "Recall on unKnown attack: 0.0001795977011493921\n",
      "F1 on unKnown attack: 0.00035913090321415525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 6/583 [00:00<00:11, 50.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Epoch 20/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 48.42it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24687\n",
      "Num attack:  12625\n",
      "------------------Epoch 21/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.78it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24621\n",
      "Num attack:  12691\n",
      "------------------Epoch 22/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.14it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24634\n",
      "Num attack:  12678\n",
      "------------------Epoch 23/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 47.98it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24609\n",
      "Num attack:  12703\n",
      "------------------Epoch 24/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 48.34it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24730\n",
      "Num attack:  12582\n",
      "------------------Epoch 25/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.35it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24636\n",
      "Num attack:  12676\n",
      "------------------Epoch 26/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 48.75it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24616\n",
      "Num attack:  12696\n",
      "------------------Epoch 27/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 48.64it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24680\n",
      "Num attack:  12632\n",
      "------------------Epoch 28/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 47.72it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24639\n",
      "Num attack:  12673\n",
      "------------------Epoch 29/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 48.19it/s]\n",
      "  4%|▍         | 56/1251 [00:00<00:02, 559.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24672\n",
      "Num attack:  12640\n",
      "Runing on validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [00:02<00:00, 550.02it/s]\n",
      "100%|██████████| 87/87 [00:00<00:00, 555.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Known attack: 0.9904576338928857\n",
      "Precision on Known attack: 0.9940494011976048\n",
      "Recall on Known attack: 0.9777295148347198\n",
      "F1 on Known attack: 0.9858219203503692\n",
      "Accuracy on unKnown attack: 0.00017959770114942528\n",
      "Precision on unKnown attack: 1.0\n",
      "Recall on unKnown attack: 0.0001795977011493921\n",
      "F1 on unKnown attack: 0.00035913090321415525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 6/583 [00:00<00:11, 51.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Epoch 30/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.07it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24652\n",
      "Num attack:  12660\n",
      "------------------Epoch 31/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 48.96it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24652\n",
      "Num attack:  12660\n",
      "------------------Epoch 32/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.80it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24639\n",
      "Num attack:  12673\n",
      "------------------Epoch 33/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.94it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24666\n",
      "Num attack:  12646\n",
      "------------------Epoch 34/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.85it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24666\n",
      "Num attack:  12646\n",
      "------------------Epoch 35/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.51it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24648\n",
      "Num attack:  12664\n",
      "------------------Epoch 36/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 47.79it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24621\n",
      "Num attack:  12691\n",
      "------------------Epoch 37/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.26it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24695\n",
      "Num attack:  12617\n",
      "------------------Epoch 38/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 48.84it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24611\n",
      "Num attack:  12701\n",
      "------------------Epoch 39/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:12<00:00, 48.51it/s]\n",
      "  4%|▍         | 56/1251 [00:00<00:02, 554.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24664\n",
      "Num attack:  12648\n",
      "Runing on validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [00:02<00:00, 564.45it/s]\n",
      "100%|██████████| 87/87 [00:00<00:00, 522.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Known attack: 0.9924560351718625\n",
      "Precision on Known attack: 0.9961880559085133\n",
      "Recall on Known attack: 0.9815155755210251\n",
      "F1 on Known attack: 0.9887973885303064\n",
      "Accuracy on unKnown attack: 0.0\n",
      "Precision on unKnown attack: nan\n",
      "Recall on unKnown attack: 0.0\n",
      "F1 on unKnown attack: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/thiennu/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  1%|          | 5/583 [00:00<00:11, 48.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Epoch 40/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:11<00:00, 49.10it/s]\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num normal:  24661\n",
      "Num attack:  12651\n",
      "------------------Epoch 41/500------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 197/583 [00:03<00:07, 49.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-15111c19c521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x_ul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x_ul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregularization_lr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupervised_encoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_input_l\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msupervised_lr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                     a_loss, d_g_loss, d_c_loss, g_loss, s_loss, summary = sess.run(\n",
      "\u001b[0;32m~/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Tensorboard visualization\n",
    "tf.summary.scalar(name='Autoencoder Loss', tensor=autoencoder_loss)\n",
    "tf.summary.scalar(name='Discriminator gauss Loss', tensor=dc_g_loss)\n",
    "tf.summary.scalar(name='Discriminator categorical Loss', tensor=dc_c_loss)\n",
    "tf.summary.scalar(name='Generator Loss', tensor=generator_loss)\n",
    "tf.summary.scalar(name='Supervised Encoder Loss', tensor=supervised_encoder_loss)\n",
    "# tf.summary.scalar(name='Supervised Encoder Accuracy', tensor=accuracy)\n",
    "tf.summary.histogram(name='Encoder Gauss Distribution', values=encoder_output_latent)\n",
    "tf.summary.histogram(name='Real Gauss Distribution', values=real_distribution)\n",
    "tf.summary.histogram(name='Encoder Categorical Distribution', values=encoder_output_label)\n",
    "tf.summary.histogram(name='Real Categorical Distribution', values=categorial_distribution)\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "accuracies = []\n",
    "# Saving the model\n",
    "saver = tf.train.Saver()\n",
    "step = 0\n",
    "# Early stopping\n",
    "save_sess = None\n",
    "best_acc = 1\n",
    "stop = False\n",
    "last_improvement = 0\n",
    "require_improvement = 20\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if True:\n",
    "        tensorboard_path, saved_model_path, log_path = form_results()\n",
    "        sess.run(init)\n",
    "        writer = tf.summary.FileWriter(logdir=tensorboard_path, graph=sess.graph)\n",
    "        for epoch in range(n_epochs):\n",
    "            if epoch == 200:\n",
    "                supervised_lr /= 10\n",
    "                reconstruction_lr /= 10\n",
    "                regularization_lr /= 10\n",
    "            n_batches = int(n_labeled / batch_size)\n",
    "            num_normal = 0\n",
    "            num_attack = 0\n",
    "            print(\"------------------Epoch {}/{}------------------\".format(epoch, n_epochs))\n",
    "            for b in tqdm.tqdm(range(1, n_batches + 1)):\n",
    "                z_real_dist = np.random.randn(batch_size, z_dim) * 5.\n",
    "                real_cat_dist = np.random.randint(low=0, high=n_labels, size=batch_size)\n",
    "                real_cat_dist = np.eye(n_labels)[real_cat_dist]\n",
    "                \n",
    "                batch_x_ul, batch_y_ul = data_stream(train_unlabel, sess)\n",
    "                batch_x_l, batch_y_l = data_stream(train_label, sess)\n",
    "                \n",
    "                if unknown_attack != '':\n",
    "                    hint_x, hint_y = data_stream(train_unlabel_unknown, sess)\n",
    "                    batch_x_ul = np.append(batch_x_ul, hint_x, axis=0)\n",
    "                    batch_y_ul = np.append(batch_y_ul, hint_y, axis=0)\n",
    "                    np.random.shuffle(batch_x_ul)\n",
    "                \n",
    "                num_normal += (np.argmax(batch_y_l, axis=1) == 0).sum()\n",
    "                num_attack += (np.argmax(batch_y_l, axis=1) == 1).sum()\n",
    "                \n",
    "                sess.run(autoencoder_optimizer, feed_dict={x_input: batch_x_ul, x_target: batch_x_ul, learning_rate: reconstruction_lr})\n",
    "                sess.run(discriminator_g_optimizer,\n",
    "                         feed_dict={x_input: batch_x_ul, x_target: batch_x_ul, real_distribution: z_real_dist, learning_rate: regularization_lr})\n",
    "                sess.run(discriminator_c_optimizer,\n",
    "                         feed_dict={x_input: batch_x_ul, x_target: batch_x_ul,\n",
    "                                    categorial_distribution: real_cat_dist, learning_rate: regularization_lr})\n",
    "                sess.run(generator_optimizer, feed_dict={x_input: batch_x_ul, x_target: batch_x_ul, learning_rate: regularization_lr})\n",
    "                \n",
    "                sess.run(supervised_encoder_optimizer, feed_dict={x_input_l: batch_x_l, y_input: batch_y_l, learning_rate: supervised_lr})\n",
    "                if b % 10 == 0:\n",
    "                    a_loss, d_g_loss, d_c_loss, g_loss, s_loss, summary = sess.run(\n",
    "                        [autoencoder_loss, dc_g_loss, dc_c_loss, generator_loss, supervised_encoder_loss,\n",
    "                         summary_op],\n",
    "                        feed_dict={x_input: batch_x_ul, x_target: batch_x_ul,\n",
    "                                   real_distribution: z_real_dist, y_input: batch_y_l, x_input_l: batch_x_l,\n",
    "                                   categorial_distribution: real_cat_dist})\n",
    "                    writer.add_summary(summary, global_step=step)\n",
    "                    with open(log_path + '/log.txt', 'a') as log:\n",
    "                        log.write(\"Epoch: {}, iteration: {}\\n\".format(epoch, b))\n",
    "                        log.write(\"Autoencoder Loss: {}\\n\".format(a_loss))\n",
    "                        log.write(\"Discriminator Gauss Loss: {}\".format(d_g_loss))\n",
    "                        log.write(\"Discriminator Categorical Loss: {}\".format(d_c_loss))\n",
    "                        log.write(\"Generator Loss: {}\\n\".format(g_loss))\n",
    "                        log.write(\"Supervised Loss: {}\".format(s_loss))\n",
    "                step += 1\n",
    "                \n",
    "            print('Num normal: ', num_normal)\n",
    "            print('Num attack: ', num_attack)\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(\"Runing on validation...\")\n",
    "                acc_known, precision_known, recall_known, f1_known = get_val_acc(validation_size, batch_size, validation)\n",
    "                print(\"Accuracy on Known attack: {}\".format(acc_known))\n",
    "                print(\"Precision on Known attack: {}\".format(precision_known))\n",
    "                print(\"Recall on Known attack: {}\".format(recall_known))\n",
    "                print(\"F1 on Known attack: {}\".format(f1_known))\n",
    "                \n",
    "                acc_unknown, precision_unknown, recall_unknown, f1_unknown = get_val_acc(validation_unknown_size, batch_size, validation_unknown)\n",
    "                print(\"Accuracy on unKnown attack: {}\".format(acc_unknown))\n",
    "                print(\"Precision on unKnown attack: {}\".format(precision_unknown))\n",
    "                print(\"Recall on unKnown attack: {}\".format(recall_unknown))\n",
    "                print(\"F1 on unKnown attack: {}\".format(f1_unknown))\n",
    "            saver.save(sess, save_path=saved_model_path, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb152c9-92e6-421a-a644-4d421e4c514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['DoS', 'Fuzzy', 'gear', 'RPM', 'Normal']\n",
    "unknown_attack = ''\n",
    "test_size = 0\n",
    "for f in ['./Data/{}/datainfo.txt'.format(l) for l in labels if l is not unknown_attack]:\n",
    "    data_read = json.load(open(f))\n",
    "    test_size += data_read['test']\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb1caa00-d6eb-4cd9-948c-8519426901cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Results/all/CNN_2021-07-21 19:53:22.883136_10_0.0001_64_300_0.9_Semi_Supervised//Saved_models/-187200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1339/1339 [00:03<00:00, 370.32it/s]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "labels = ['DoS', 'Fuzzy', 'gear', 'RPM', 'Normal']\n",
    "# test_paths = glob.glob(data_path + 'test')\n",
    "with tf.Session() as sess:\n",
    "    #attack = 'gear'\n",
    "    data_path = ['./Data/{}/'.format(a) for a in labels]\n",
    "    results_path = './Results/all/CNN_2021-07-21 19:53:22.883136_10_0.0001_64_300_0.9_Semi_Supervised/'\n",
    "    #data_info = json.load(open(data_path + 'datainfo.txt'))\n",
    "    \n",
    "    # Get the latest results folder\n",
    "    #all_results = os.listdir(results_path)\n",
    "    #all_results.sort()\n",
    "    \n",
    "    #saver.restore(sess, save_path=tf.train.latest_checkpoint(results_path + '/' +\n",
    "    #                                                         all_results[1] + '/Saved_models/'))\n",
    "    saver.restore(sess, save_path=tf.train.latest_checkpoint(results_path + '/Saved_models'))\n",
    "    \n",
    "    test = data_from_tfrecord([p + 'test' for p in data_path], batch_size, 1)\n",
    "    \n",
    "    num_batches = int(test_size / batch_size)\n",
    "    y_true = np.empty((0), int)\n",
    "    y_pred = np.empty((0), int)\n",
    "    total_prob = np.empty((0), float)\n",
    "    total_latent = np.empty((0, z_dim), float)\n",
    "    for _ in tqdm.tqdm(range(num_batches)):\n",
    "        x_test, y_test = data_stream(test, sess)\n",
    "        batch_pred, batch_latent = sess.run([encoder_output_label_, encoder_output_latent], feed_dict={x_input_l: x_test})\n",
    "        total_latent = np.append(total_latent, batch_latent, axis=0)\n",
    "        batch_label = np.argmax(y_test, axis=1).reshape((batch_size))\n",
    "        prob = np.max(batch_pred, axis=1).reshape((batch_size))\n",
    "        batch_pred = np.argmax(batch_pred, axis=1).reshape((batch_size))\n",
    "        y_pred = np.append(y_pred, batch_pred, axis=0)\n",
    "        y_true = np.append(y_true, batch_label, axis=0)  \n",
    "        total_prob = np.append(total_prob, prob, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17aecd52-a214-4484-a148-fa0056e9474d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32520 267\n",
      "30 52879\n",
      "False negative rate:  0.008143471497849757\n",
      "Error rate:  0.003465739357729649\n",
      "Precision:  0.9990783410138249\n",
      "Recall:  0.9918565285021502\n",
      "F1 score:  0.9954543367464072\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e71ea2-2da2-4e14-8af0-c2ff00b2b5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Tensorflow1.x] *",
   "language": "python",
   "name": "conda-env-Tensorflow1.x-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
