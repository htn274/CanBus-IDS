{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b74145f-5752-4a67-b662-2f778badf2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import layers, models\n",
    "from utils import *\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c42bf569-e11c-4b93-8249-99bb5efe6e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data info:  {'train_unlabel': 359956, 'train_label': 39993, 'validation': 85701, 'test': 85701}\n",
      "Num labeled normal:  24693\n",
      "Num labeled attack:  15300\n"
     ]
    }
   ],
   "source": [
    "data_info = {\n",
    "   \"train_unlabel\": 0, \n",
    "    \"train_label\": 0, \n",
    "    \"validation\": 0, \n",
    "    \"test\": 0\n",
    "}\n",
    "labels = ['DoS', 'Fuzzy', 'gear', 'RPM', 'Normal']\n",
    "unknown_attack = ''\n",
    "num_normal = 0\n",
    "num_attack = 0\n",
    "for f in ['./Data/{}/datainfo.txt'.format(l) for l in labels if l is not unknown_attack]:\n",
    "    data_read = json.load(open(f))\n",
    "    for key in data_info.keys():\n",
    "        data_info[key] += data_read[key]\n",
    "    if 'Normal' in f:\n",
    "        num_normal += data_read['train_label']\n",
    "    else:\n",
    "        num_attack += data_read['train_label']\n",
    "        \n",
    "attack = 'all' # DoS, Fuzzy, gear, RPM, all\n",
    "if unknown_attack != '':\n",
    "    results_path = './Results/unknown/{}'.format(unknown_attack)\n",
    "else:\n",
    "    results_path = './Results/{}/'.format(attack)\n",
    "print('Data info: ', data_info)\n",
    "print('Num labeled normal: ', num_normal)\n",
    "print('Num labeled attack: ', num_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b147b7fa-26fc-44ea-8619-38b4bf3fd093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train unlabel:  ['./Data/DoS/train_label', './Data/Fuzzy/train_label', './Data/gear/train_label', './Data/RPM/train_label', './Data/Normal/train_label']\n",
      "Train label:  ['./Data/DoS/train_label', './Data/Fuzzy/train_label', './Data/gear/train_label', './Data/RPM/train_label', './Data/Normal/train_label']\n",
      "Validation:  ['./Data/DoS/val', './Data/Fuzzy/val', './Data/gear/val', './Data/RPM/val', './Data/Normal/val']\n"
     ]
    }
   ],
   "source": [
    "train_unlabel_paths = ['./Data/{}/train_unlabel'.format(l) for l in labels if l is not unknown_attack]\n",
    "train_label_paths = ['./Data/{}/train_label'.format(l) for l in labels if l is not unknown_attack]\n",
    "val_paths = ['./Data/{}/val'.format(l) for l in labels if l is not unknown_attack]\n",
    "test_paths = ['./Data/{}/test'.format(l) for l in labels if l is not unknown_attack]\n",
    "\n",
    "train_label = data_from_tfrecord(train_label_paths, data_info['train_label'], 1)\n",
    "validation = data_from_tfrecord(val_paths,  data_info['validation'], 1)\n",
    "test = data_from_tfrecord(test_paths, data_info['test'], 1)\n",
    "\n",
    "print('Train unlabel: ', train_label_paths)\n",
    "print('Train label: ', train_label_paths)\n",
    "print('Validation: ', val_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51aa1b1c-8bd9-4c6b-831b-a36def384d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (39993, 841) (39993,)\n",
      "Validation:  (85701, 841) (39993,)\n",
      "Test:  (85701, 841) (85701,)\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    X_train, y_train = data_stream(train_label, sess)\n",
    "    X_val, y_val = data_stream(validation, sess)\n",
    "    X_test, y_test = data_stream(test, sess)\n",
    "    y_train = np.argmax(y_train, axis=1)\n",
    "    y_val = np.argmax(y_val, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    print('Train: ', X_train.shape, y_train.shape)\n",
    "    print('Validation: ', X_val.shape, y_train.shape)\n",
    "    print('Test: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "847fcca1-c665-49e8-94e6-33395e66bb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiennu/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes = (1000, 1000), random_state=1, max_iter=500).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c15a5ad-f7e8-4890-897d-971eaf7997b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f7a4cc69b9a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \"\"\"\n\u001b[1;32m   1036\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass_fast\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mactivation\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mhidden_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665e4f13-120c-4d43-86e3-3c74031a70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eff91f6e-3a30-4bc8-9e9f-5fcb647a50d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(1000, input_dim=841, activation='relu'),\n",
    "  tf.keras.layers.Dense(1000, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1933f73-b4e1-4589-a3aa-852378da58a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thiennu/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss= 'binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7ef884a-af37-4dc8-9a60-eb25b28ed2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39993 samples, validate on 85701 samples\n",
      "Epoch 1/30\n",
      "39993/39993 [==============================] - 2s 50us/sample - loss: 2.4991e-10 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 0.9923\n",
      "Epoch 2/30\n",
      "39993/39993 [==============================] - 2s 49us/sample - loss: 2.3862e-10 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9923\n",
      "Epoch 3/30\n",
      "39993/39993 [==============================] - 2s 49us/sample - loss: 2.2996e-10 - acc: 1.0000 - val_loss: 0.0978 - val_acc: 0.9922\n",
      "Epoch 4/30\n",
      "39993/39993 [==============================] - 2s 50us/sample - loss: 2.2470e-10 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9922\n",
      "Epoch 5/30\n",
      "39993/39993 [==============================] - 2s 50us/sample - loss: 2.1797e-10 - acc: 1.0000 - val_loss: 0.0992 - val_acc: 0.9922\n",
      "Epoch 6/30\n",
      "39993/39993 [==============================] - 2s 50us/sample - loss: 2.1351e-10 - acc: 1.0000 - val_loss: 0.0996 - val_acc: 0.9922\n",
      "Epoch 7/30\n",
      "39993/39993 [==============================] - 2s 50us/sample - loss: 2.1087e-10 - acc: 1.0000 - val_loss: 0.0999 - val_acc: 0.9922\n",
      "Epoch 8/30\n",
      "39993/39993 [==============================] - 2s 51us/sample - loss: 2.0628e-10 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9921\n",
      "Epoch 9/30\n",
      "39993/39993 [==============================] - 2s 51us/sample - loss: 2.0308e-10 - acc: 1.0000 - val_loss: 0.1013 - val_acc: 0.9921\n",
      "Epoch 10/30\n",
      "39993/39993 [==============================] - 2s 50us/sample - loss: 2.0365e-10 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9921\n",
      "Epoch 11/30\n",
      "39993/39993 [==============================] - 2s 50us/sample - loss: 2.0437e-10 - acc: 1.0000 - val_loss: 0.1018 - val_acc: 0.9921\n",
      "Epoch 12/30\n",
      "39993/39993 [==============================] - 2s 50us/sample - loss: 2.0396e-10 - acc: 1.0000 - val_loss: 0.1026 - val_acc: 0.9921\n",
      "Epoch 13/30\n",
      "39993/39993 [==============================] - 2s 50us/sample - loss: 2.0198e-10 - acc: 1.0000 - val_loss: 0.1029 - val_acc: 0.9921\n",
      "Epoch 14/30\n",
      "39993/39993 [==============================] - 2s 52us/sample - loss: 2.0093e-10 - acc: 1.0000 - val_loss: 0.1031 - val_acc: 0.9920\n",
      "Epoch 15/30\n",
      "39993/39993 [==============================] - 2s 54us/sample - loss: 1.9930e-10 - acc: 1.0000 - val_loss: 0.1033 - val_acc: 0.9920\n",
      "Epoch 16/30\n",
      "39993/39993 [==============================] - 2s 48us/sample - loss: 1.9848e-10 - acc: 1.0000 - val_loss: 0.1036 - val_acc: 0.9920\n",
      "Epoch 17/30\n",
      "39993/39993 [==============================] - 2s 54us/sample - loss: 1.9844e-10 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9920\n",
      "Epoch 18/30\n",
      "39993/39993 [==============================] - 2s 56us/sample - loss: 1.9533e-10 - acc: 1.0000 - val_loss: 0.1043 - val_acc: 0.9920\n",
      "Epoch 19/30\n",
      "39993/39993 [==============================] - 2s 51us/sample - loss: 1.9518e-10 - acc: 1.0000 - val_loss: 0.1045 - val_acc: 0.9920\n",
      "Epoch 20/30\n",
      "39993/39993 [==============================] - 2s 51us/sample - loss: 1.9819e-10 - acc: 1.0000 - val_loss: 0.1046 - val_acc: 0.9920\n",
      "Epoch 21/30\n",
      "39993/39993 [==============================] - 2s 50us/sample - loss: 1.9443e-10 - acc: 1.0000 - val_loss: 0.1049 - val_acc: 0.9920\n",
      "Epoch 22/30\n",
      "39993/39993 [==============================] - 2s 51us/sample - loss: 1.9487e-10 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9919\n",
      "Epoch 23/30\n",
      "39993/39993 [==============================] - 2s 51us/sample - loss: 1.9565e-10 - acc: 1.0000 - val_loss: 0.1055 - val_acc: 0.9920\n",
      "Epoch 24/30\n",
      "39993/39993 [==============================] - 2s 51us/sample - loss: 1.9530e-10 - acc: 1.0000 - val_loss: 0.1056 - val_acc: 0.9920\n",
      "Epoch 25/30\n",
      "39993/39993 [==============================] - 2s 52us/sample - loss: 1.9447e-10 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9919\n",
      "Epoch 26/30\n",
      "39993/39993 [==============================] - 2s 51us/sample - loss: 1.9516e-10 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9919\n",
      "Epoch 27/30\n",
      "39993/39993 [==============================] - 2s 52us/sample - loss: 1.9421e-10 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9919\n",
      "Epoch 28/30\n",
      "39993/39993 [==============================] - 2s 51us/sample - loss: 1.9076e-10 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9919\n",
      "Epoch 29/30\n",
      "39993/39993 [==============================] - 2s 51us/sample - loss: 1.9197e-10 - acc: 1.0000 - val_loss: 0.1066 - val_acc: 0.9919\n",
      "Epoch 30/30\n",
      "39993/39993 [==============================] - 2s 51us/sample - loss: 1.9163e-10 - acc: 1.0000 - val_loss: 0.1068 - val_acc: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f04800e68d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=100, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebf1d55a-cbfc-4b01-967a-6f1d00ba5eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30956 1835\n",
      "1 52909\n",
      "False negative rate:  0.0559604769601415\n",
      "Error rate:  0.021423320614695276\n",
      "Precision:  0.9999676971282747\n",
      "Recall:  0.9440395230398585\n",
      "F1 score:  0.9711990964422414\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).flatten().astype(int)\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bedb02d6-3f01-4662-ac7c-d9d4cce2cb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thiennu/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 29, 29, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 65,122\n",
      "Trainable params: 65,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(29, 29, 1))) #[29, 29, 1] -> [29, 29, 32]\n",
    "model.add(layers.MaxPooling2D((2, 2))) #[29, 29, 32] -> [14, 14, 32]\n",
    "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(2, activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0387561f-a3da-4776-ae31-32d3c86a672c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39993 samples, validate on 85701 samples\n",
      "Epoch 1/10\n",
      "39993/39993 [==============================] - 5s 119us/sample - loss: 8.6545e-04 - acc: 0.9997 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Epoch 2/10\n",
      "39993/39993 [==============================] - 5s 116us/sample - loss: 1.1196e-04 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9985\n",
      "Epoch 3/10\n",
      "39993/39993 [==============================] - 5s 115us/sample - loss: 6.2849e-04 - acc: 0.9999 - val_loss: 0.0552 - val_acc: 0.9922\n",
      "Epoch 4/10\n",
      "39993/39993 [==============================] - 5s 120us/sample - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0129 - val_acc: 0.9983\n",
      "Epoch 5/10\n",
      "39993/39993 [==============================] - 5s 126us/sample - loss: 6.0092e-04 - acc: 0.9998 - val_loss: 0.0083 - val_acc: 0.9987\n",
      "Epoch 6/10\n",
      "39993/39993 [==============================] - 5s 116us/sample - loss: 1.0856e-04 - acc: 0.9999 - val_loss: 0.0215 - val_acc: 0.9980\n",
      "Epoch 7/10\n",
      "39993/39993 [==============================] - 5s 113us/sample - loss: 4.8018e-05 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 0.9985\n",
      "Epoch 8/10\n",
      "39993/39993 [==============================] - 5s 120us/sample - loss: 2.1561e-06 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 0.9985\n",
      "Epoch 9/10\n",
      "39993/39993 [==============================] - 5s 117us/sample - loss: 5.6278e-07 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 0.9985\n",
      "Epoch 10/10\n",
      "39993/39993 [==============================] - 5s 114us/sample - loss: 3.6096e-07 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 0.9985\n"
     ]
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 29, 29, 1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], 29, 29, 1))\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, \n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc7e3818-0ad9-421f-b5a2-b226d1791d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test, (X_test.shape[0], 29, 29, 1))\n",
    "# y_test = np.argmax(y_test, axis=1)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a02ace1d-ab46-442b-a835-a7a5e319d447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32650 141\n",
      "6 52904\n",
      "False negative rate:  0.00429996035497545\n",
      "Error rate:  0.0017152658662092624\n",
      "Precision:  0.9998162665360117\n",
      "Recall:  0.9957000396450245\n",
      "F1 score:  0.9977539077421425\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2b037-c04b-48d6-9ca2-f259ac3715d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Tensorflow1.x] *",
   "language": "python",
   "name": "conda-env-Tensorflow1.x-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
