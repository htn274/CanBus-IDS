{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b74145f-5752-4a67-b662-2f778badf2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import layers, models\n",
    "from utils import *\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c42bf569-e11c-4b93-8249-99bb5efe6e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data info:  {'train_unlabel': 281262, 'train_label': 31249, 'validation': 96632, 'test': 118490}\n",
      "Num labeled normal:  24693\n",
      "Num labeled attack:  6556\n"
     ]
    }
   ],
   "source": [
    "data_info = {\n",
    "   \"train_unlabel\": 0, \n",
    "    \"train_label\": 0, \n",
    "    \"validation\": 0, \n",
    "    \"test\": 0\n",
    "}\n",
    "labels = ['DoS', 'Fuzzy', 'gear', 'RPM', 'Normal']\n",
    "unknown_attack = ''\n",
    "num_normal = 0\n",
    "num_attack = 0\n",
    "data_dir = './Data/Train_0.3_Labeled_0.1/'\n",
    "for f in ['{}/{}/datainfo.txt'.format(data_dir, l) for l in labels if l is not unknown_attack]:\n",
    "    data_read = json.load(open(f))\n",
    "    for key in data_info.keys():\n",
    "        data_info[key] += data_read[key]\n",
    "    if 'Normal' in f:\n",
    "        num_normal += data_read['train_label']\n",
    "    else:\n",
    "        num_attack += data_read['train_label']\n",
    "        \n",
    "print('Data info: ', data_info)\n",
    "print('Num labeled normal: ', num_normal)\n",
    "print('Num labeled attack: ', num_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b147b7fa-26fc-44ea-8619-38b4bf3fd093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thiennu/Research/IDS/utils.py:25: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "Train unlabel:  ['./Data/Train_0.3_Labeled_0.1//DoS/train_label', './Data/Train_0.3_Labeled_0.1//Fuzzy/train_label', './Data/Train_0.3_Labeled_0.1//gear/train_label', './Data/Train_0.3_Labeled_0.1//RPM/train_label', './Data/Train_0.3_Labeled_0.1//Normal/train_label']\n",
      "Train label:  ['./Data/Train_0.3_Labeled_0.1//DoS/train_label', './Data/Train_0.3_Labeled_0.1//Fuzzy/train_label', './Data/Train_0.3_Labeled_0.1//gear/train_label', './Data/Train_0.3_Labeled_0.1//RPM/train_label', './Data/Train_0.3_Labeled_0.1//Normal/train_label']\n",
      "Validation:  ['./Data/Train_0.3_Labeled_0.1//DoS/val', './Data/Train_0.3_Labeled_0.1//Fuzzy/val', './Data/Train_0.3_Labeled_0.1//gear/val', './Data/Train_0.3_Labeled_0.1//RPM/val', './Data/Train_0.3_Labeled_0.1//Normal/val']\n"
     ]
    }
   ],
   "source": [
    "train_unlabel_paths = ['{}/{}/train_unlabel'.format(data_dir, l) for l in labels if l is not unknown_attack]\n",
    "train_label_paths = ['{}/{}/train_label'.format(data_dir, l) for l in labels if l is not unknown_attack]\n",
    "val_paths = ['{}/{}/val'.format(data_dir, l) for l in labels if l is not unknown_attack]\n",
    "test_paths = ['{}/{}/test'.format(data_dir, l) for l in labels if l is not unknown_attack]\n",
    "\n",
    "train_label = data_from_tfrecord(train_label_paths, data_info['train_label'], 1)\n",
    "validation = data_from_tfrecord(val_paths,  data_info['validation'], 1)\n",
    "test = data_from_tfrecord(test_paths, data_info['test'], 1)\n",
    "\n",
    "print('Train unlabel: ', train_label_paths)\n",
    "print('Train label: ', train_label_paths)\n",
    "print('Validation: ', val_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51aa1b1c-8bd9-4c6b-831b-a36def384d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (31249, 841) (31249,)\n",
      "Validation:  (96632, 841) (31249,)\n",
      "Test:  (118490, 841) (118490,)\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session(config=tf.ConfigProto(device_count={'GPU':0})) as sess:\n",
    "    X_train, y_train = data_stream(train_label, sess)\n",
    "    X_val, y_val = data_stream(validation, sess)\n",
    "    X_test, y_test = data_stream(test, sess)\n",
    "    y_train = np.argmax(y_train, axis=1)\n",
    "    y_val = np.argmax(y_val, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    print('Train: ', X_train.shape, y_train.shape)\n",
    "    print('Validation: ', X_val.shape, y_train.shape)\n",
    "    print('Test: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c26e39-488b-43b1-b345-b1d3c7812634",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eba8c31a-f025-4dbb-8719-0ebc0d344658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7618be7-882b-4b01-ac88-d82f0f94cf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79370 2972\n",
      "7 36141\n",
      "False negative rate:  0.03609336669014598\n",
      "Error rate:  0.025141362140265\n",
      "Precision:  0.9999118132456505\n",
      "Recall:  0.963906633309854\n",
      "F1 score:  0.9815791589114452\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b253b9f-6b61-4a82-94ed-548ad5a5f277",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "720bbdf2-09b8-4a3a-8e6a-fd5d73178454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dst = DecisionTreeClassifier(random_state=0)\n",
    "dst.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63288a7e-20df-469f-b098-e3ae8f48c817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66827 15515\n",
      "1112 35036\n",
      "False negative rate:  0.18842146170848412\n",
      "Error rate:  0.14032407798126423\n",
      "Precision:  0.9836323761020915\n",
      "Recall:  0.8115785382915159\n",
      "F1 score:  0.8893605978134296\n"
     ]
    }
   ],
   "source": [
    "y_pred = dst.predict(X_test)\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2e3e2-4f3f-4c40-92a1-b79d1b7b08c8",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff91f6e-3a30-4bc8-9e9f-5fcb647a50d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thiennu/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(1000, input_dim=841, activation='relu'),\n",
    "  tf.keras.layers.Dense(1000, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1933f73-b4e1-4589-a3aa-852378da58a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thiennu/miniconda3/envs/Tensorflow1.x/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss= 'binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7ef884a-af37-4dc8-9a60-eb25b28ed2b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31249 samples, validate on 96632 samples\n",
      "Epoch 1/200\n",
      "31249/31249 [==============================] - 2s 67us/sample - loss: 0.0947 - acc: 0.9674 - val_loss: 0.1805 - val_acc: 0.9424\n",
      "Epoch 2/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0273 - acc: 0.9916 - val_loss: 0.0428 - val_acc: 0.9874\n",
      "Epoch 3/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0143 - acc: 0.9957 - val_loss: 0.0720 - val_acc: 0.9806\n",
      "Epoch 4/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0101 - acc: 0.9963 - val_loss: 0.0971 - val_acc: 0.9765\n",
      "Epoch 5/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0748 - val_acc: 0.9851\n",
      "Epoch 6/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 0.0107 - acc: 0.9964 - val_loss: 0.0875 - val_acc: 0.9809\n",
      "Epoch 7/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0869 - val_acc: 0.9827\n",
      "Epoch 8/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 0.0021 - acc: 0.9992 - val_loss: 0.0691 - val_acc: 0.9871\n",
      "Epoch 9/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0658 - val_acc: 0.9852\n",
      "Epoch 10/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0050 - acc: 0.9984 - val_loss: 0.1413 - val_acc: 0.9728\n",
      "Epoch 11/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0736 - val_acc: 0.9850\n",
      "Epoch 12/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0765 - val_acc: 0.9840\n",
      "Epoch 13/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0023 - acc: 0.9992 - val_loss: 0.1189 - val_acc: 0.9788\n",
      "Epoch 14/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 0.0028 - acc: 0.9990 - val_loss: 0.1527 - val_acc: 0.9764\n",
      "Epoch 15/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0018 - acc: 0.9993 - val_loss: 0.2803 - val_acc: 0.9632\n",
      "Epoch 16/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0963 - val_acc: 0.9815\n",
      "Epoch 17/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 0.0010 - acc: 0.9997 - val_loss: 0.1362 - val_acc: 0.9797\n",
      "Epoch 18/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0633 - val_acc: 0.9868\n",
      "Epoch 19/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0020 - acc: 0.9994 - val_loss: 0.1073 - val_acc: 0.9837\n",
      "Epoch 20/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0578 - val_acc: 0.9882\n",
      "Epoch 21/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0029 - acc: 0.9990 - val_loss: 0.0991 - val_acc: 0.9842\n",
      "Epoch 22/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0030 - acc: 0.9989 - val_loss: 0.1785 - val_acc: 0.9706\n",
      "Epoch 23/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0011 - acc: 0.9996 - val_loss: 0.1584 - val_acc: 0.9799\n",
      "Epoch 24/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0029 - acc: 0.9989 - val_loss: 0.1402 - val_acc: 0.9797\n",
      "Epoch 25/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 0.0023 - acc: 0.9992 - val_loss: 0.1473 - val_acc: 0.9780\n",
      "Epoch 26/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 2.0133e-04 - acc: 1.0000 - val_loss: 0.1031 - val_acc: 0.9860\n",
      "Epoch 27/200\n",
      "31249/31249 [==============================] - 2s 63us/sample - loss: 2.3108e-05 - acc: 1.0000 - val_loss: 0.0774 - val_acc: 0.9888\n",
      "Epoch 28/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.5048e-05 - acc: 1.0000 - val_loss: 0.1449 - val_acc: 0.9827\n",
      "Epoch 29/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.1122e-06 - acc: 1.0000 - val_loss: 0.1424 - val_acc: 0.9833\n",
      "Epoch 30/200\n",
      "31249/31249 [==============================] - 2s 62us/sample - loss: 6.6060e-07 - acc: 1.0000 - val_loss: 0.1442 - val_acc: 0.9836\n",
      "Epoch 31/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 3.8039e-07 - acc: 1.0000 - val_loss: 0.1498 - val_acc: 0.9836\n",
      "Epoch 32/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 2.3725e-07 - acc: 1.0000 - val_loss: 0.1554 - val_acc: 0.9835\n",
      "Epoch 33/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.6583e-07 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.9837\n",
      "Epoch 34/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.2928e-07 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.9836\n",
      "Epoch 35/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.0277e-07 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 0.9835\n",
      "Epoch 36/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 8.4095e-08 - acc: 1.0000 - val_loss: 0.1692 - val_acc: 0.9833\n",
      "Epoch 37/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 7.1253e-08 - acc: 1.0000 - val_loss: 0.1667 - val_acc: 0.9837\n",
      "Epoch 38/200\n",
      "31249/31249 [==============================] - 2s 57us/sample - loss: 6.0240e-08 - acc: 1.0000 - val_loss: 0.1680 - val_acc: 0.9837\n",
      "Epoch 39/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 5.0975e-08 - acc: 1.0000 - val_loss: 0.1717 - val_acc: 0.9835\n",
      "Epoch 40/200\n",
      "31249/31249 [==============================] - 2s 63us/sample - loss: 4.4240e-08 - acc: 1.0000 - val_loss: 0.1700 - val_acc: 0.9837\n",
      "Epoch 41/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 3.8307e-08 - acc: 1.0000 - val_loss: 0.1725 - val_acc: 0.9837\n",
      "Epoch 42/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 3.3265e-08 - acc: 1.0000 - val_loss: 0.1720 - val_acc: 0.9838\n",
      "Epoch 43/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 2.9104e-08 - acc: 1.0000 - val_loss: 0.1740 - val_acc: 0.9837\n",
      "Epoch 44/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 2.5675e-08 - acc: 1.0000 - val_loss: 0.1751 - val_acc: 0.9837\n",
      "Epoch 45/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 2.2386e-08 - acc: 1.0000 - val_loss: 0.1762 - val_acc: 0.9837\n",
      "Epoch 46/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.9601e-08 - acc: 1.0000 - val_loss: 0.1773 - val_acc: 0.9837\n",
      "Epoch 47/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.7329e-08 - acc: 1.0000 - val_loss: 0.1770 - val_acc: 0.9837\n",
      "Epoch 48/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.5272e-08 - acc: 1.0000 - val_loss: 0.1759 - val_acc: 0.9838\n",
      "Epoch 49/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.3590e-08 - acc: 1.0000 - val_loss: 0.1778 - val_acc: 0.9837\n",
      "Epoch 50/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.2023e-08 - acc: 1.0000 - val_loss: 0.1778 - val_acc: 0.9838\n",
      "Epoch 51/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.0720e-08 - acc: 1.0000 - val_loss: 0.1790 - val_acc: 0.9837\n",
      "Epoch 52/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 9.5218e-09 - acc: 1.0000 - val_loss: 0.1809 - val_acc: 0.9837\n",
      "Epoch 53/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 8.4777e-09 - acc: 1.0000 - val_loss: 0.1823 - val_acc: 0.9836\n",
      "Epoch 54/200\n",
      "31249/31249 [==============================] - 2s 62us/sample - loss: 7.5640e-09 - acc: 1.0000 - val_loss: 0.1805 - val_acc: 0.9838\n",
      "Epoch 55/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 6.7301e-09 - acc: 1.0000 - val_loss: 0.1815 - val_acc: 0.9838\n",
      "Epoch 56/200\n",
      "31249/31249 [==============================] - 2s 62us/sample - loss: 6.0010e-09 - acc: 1.0000 - val_loss: 0.1821 - val_acc: 0.9838\n",
      "Epoch 57/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 5.3506e-09 - acc: 1.0000 - val_loss: 0.1830 - val_acc: 0.9838\n",
      "Epoch 58/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 4.7624e-09 - acc: 1.0000 - val_loss: 0.1827 - val_acc: 0.9839\n",
      "Epoch 59/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 4.2392e-09 - acc: 1.0000 - val_loss: 0.1847 - val_acc: 0.9837\n",
      "Epoch 60/200\n",
      "31249/31249 [==============================] - 2s 57us/sample - loss: 3.7940e-09 - acc: 1.0000 - val_loss: 0.1858 - val_acc: 0.9837\n",
      "Epoch 61/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 3.3699e-09 - acc: 1.0000 - val_loss: 0.1863 - val_acc: 0.9837\n",
      "Epoch 62/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 2.9994e-09 - acc: 1.0000 - val_loss: 0.1870 - val_acc: 0.9838\n",
      "Epoch 63/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 2.6782e-09 - acc: 1.0000 - val_loss: 0.1870 - val_acc: 0.9838\n",
      "Epoch 64/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 2.3788e-09 - acc: 1.0000 - val_loss: 0.1882 - val_acc: 0.9838\n",
      "Epoch 65/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 2.1184e-09 - acc: 1.0000 - val_loss: 0.1891 - val_acc: 0.9838\n",
      "Epoch 66/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.8890e-09 - acc: 1.0000 - val_loss: 0.1899 - val_acc: 0.9838\n",
      "Epoch 67/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6749e-09 - acc: 1.0000 - val_loss: 0.1902 - val_acc: 0.9839\n",
      "Epoch 68/200\n",
      "31249/31249 [==============================] - 2s 57us/sample - loss: 1.4868e-09 - acc: 1.0000 - val_loss: 0.1908 - val_acc: 0.9839\n",
      "Epoch 69/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.3230e-09 - acc: 1.0000 - val_loss: 0.1917 - val_acc: 0.9839\n",
      "Epoch 70/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.1761e-09 - acc: 1.0000 - val_loss: 0.1930 - val_acc: 0.9839\n",
      "Epoch 71/200\n",
      "31249/31249 [==============================] - 2s 57us/sample - loss: 1.0472e-09 - acc: 1.0000 - val_loss: 0.1935 - val_acc: 0.9839\n",
      "Epoch 72/200\n",
      "31249/31249 [==============================] - 2s 57us/sample - loss: 9.3297e-10 - acc: 1.0000 - val_loss: 0.1948 - val_acc: 0.9838\n",
      "Epoch 73/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 8.2969e-10 - acc: 1.0000 - val_loss: 0.1961 - val_acc: 0.9838\n",
      "Epoch 74/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 7.3767e-10 - acc: 1.0000 - val_loss: 0.1970 - val_acc: 0.9838\n",
      "Epoch 75/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 6.6032e-10 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9838\n",
      "Epoch 76/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 5.9215e-10 - acc: 1.0000 - val_loss: 0.1988 - val_acc: 0.9838\n",
      "Epoch 77/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 5.2963e-10 - acc: 1.0000 - val_loss: 0.2005 - val_acc: 0.9838\n",
      "Epoch 78/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 4.8185e-10 - acc: 1.0000 - val_loss: 0.2008 - val_acc: 0.9838\n",
      "Epoch 79/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 4.3644e-10 - acc: 1.0000 - val_loss: 0.2015 - val_acc: 0.9838\n",
      "Epoch 80/200\n",
      "31249/31249 [==============================] - 2s 57us/sample - loss: 3.9055e-10 - acc: 1.0000 - val_loss: 0.2030 - val_acc: 0.9838\n",
      "Epoch 81/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 3.5989e-10 - acc: 1.0000 - val_loss: 0.2040 - val_acc: 0.9838\n",
      "Epoch 82/200\n",
      "31249/31249 [==============================] - 2s 57us/sample - loss: 3.2947e-10 - acc: 1.0000 - val_loss: 0.2057 - val_acc: 0.9837\n",
      "Epoch 83/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 3.0691e-10 - acc: 1.0000 - val_loss: 0.2065 - val_acc: 0.9837\n",
      "Epoch 84/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 2.8472e-10 - acc: 1.0000 - val_loss: 0.2080 - val_acc: 0.9837\n",
      "Epoch 85/200\n",
      "31249/31249 [==============================] - 2s 63us/sample - loss: 2.6407e-10 - acc: 1.0000 - val_loss: 0.2092 - val_acc: 0.9836\n",
      "Epoch 86/200\n",
      "31249/31249 [==============================] - 2s 64us/sample - loss: 2.4853e-10 - acc: 1.0000 - val_loss: 0.2105 - val_acc: 0.9836\n",
      "Epoch 87/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 2.3724e-10 - acc: 1.0000 - val_loss: 0.2123 - val_acc: 0.9836\n",
      "Epoch 88/200\n",
      "31249/31249 [==============================] - 2s 64us/sample - loss: 2.2792e-10 - acc: 1.0000 - val_loss: 0.2133 - val_acc: 0.9836\n",
      "Epoch 89/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 2.1778e-10 - acc: 1.0000 - val_loss: 0.2146 - val_acc: 0.9835\n",
      "Epoch 90/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 2.1172e-10 - acc: 1.0000 - val_loss: 0.2161 - val_acc: 0.9834\n",
      "Epoch 91/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 2.0609e-10 - acc: 1.0000 - val_loss: 0.2165 - val_acc: 0.9834\n",
      "Epoch 92/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.9874e-10 - acc: 1.0000 - val_loss: 0.2184 - val_acc: 0.9833\n",
      "Epoch 93/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.9610e-10 - acc: 1.0000 - val_loss: 0.2193 - val_acc: 0.9833\n",
      "Epoch 94/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.9350e-10 - acc: 1.0000 - val_loss: 0.2197 - val_acc: 0.9833\n",
      "Epoch 95/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.8930e-10 - acc: 1.0000 - val_loss: 0.2210 - val_acc: 0.9832\n",
      "Epoch 96/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.8676e-10 - acc: 1.0000 - val_loss: 0.2225 - val_acc: 0.9832\n",
      "Epoch 97/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.8626e-10 - acc: 1.0000 - val_loss: 0.2230 - val_acc: 0.9831\n",
      "Epoch 98/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.8348e-10 - acc: 1.0000 - val_loss: 0.2236 - val_acc: 0.9831\n",
      "Epoch 99/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.8115e-10 - acc: 1.0000 - val_loss: 0.2247 - val_acc: 0.9830\n",
      "Epoch 100/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.8064e-10 - acc: 1.0000 - val_loss: 0.2255 - val_acc: 0.9830\n",
      "Epoch 101/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.8071e-10 - acc: 1.0000 - val_loss: 0.2266 - val_acc: 0.9830\n",
      "Epoch 102/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.7874e-10 - acc: 1.0000 - val_loss: 0.2264 - val_acc: 0.9830\n",
      "Epoch 103/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.7598e-10 - acc: 1.0000 - val_loss: 0.2274 - val_acc: 0.9830\n",
      "Epoch 104/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.7553e-10 - acc: 1.0000 - val_loss: 0.2285 - val_acc: 0.9829\n",
      "Epoch 105/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.7650e-10 - acc: 1.0000 - val_loss: 0.2284 - val_acc: 0.9829\n",
      "Epoch 106/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.7486e-10 - acc: 1.0000 - val_loss: 0.2292 - val_acc: 0.9829\n",
      "Epoch 107/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.7423e-10 - acc: 1.0000 - val_loss: 0.2292 - val_acc: 0.9829\n",
      "Epoch 108/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6994e-10 - acc: 1.0000 - val_loss: 0.2307 - val_acc: 0.9829\n",
      "Epoch 109/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.7373e-10 - acc: 1.0000 - val_loss: 0.2317 - val_acc: 0.9828\n",
      "Epoch 110/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.7497e-10 - acc: 1.0000 - val_loss: 0.2319 - val_acc: 0.9828\n",
      "Epoch 111/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.7257e-10 - acc: 1.0000 - val_loss: 0.2326 - val_acc: 0.9828\n",
      "Epoch 112/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.7141e-10 - acc: 1.0000 - val_loss: 0.2330 - val_acc: 0.9827\n",
      "Epoch 113/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.7282e-10 - acc: 1.0000 - val_loss: 0.2331 - val_acc: 0.9827\n",
      "Epoch 114/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.7255e-10 - acc: 1.0000 - val_loss: 0.2338 - val_acc: 0.9827\n",
      "Epoch 115/200\n",
      "31249/31249 [==============================] - 2s 67us/sample - loss: 1.7310e-10 - acc: 1.0000 - val_loss: 0.2340 - val_acc: 0.9827\n",
      "Epoch 116/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.7018e-10 - acc: 1.0000 - val_loss: 0.2343 - val_acc: 0.9827\n",
      "Epoch 117/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.7020e-10 - acc: 1.0000 - val_loss: 0.2349 - val_acc: 0.9827\n",
      "Epoch 118/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.7167e-10 - acc: 1.0000 - val_loss: 0.2354 - val_acc: 0.9827\n",
      "Epoch 119/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.7124e-10 - acc: 1.0000 - val_loss: 0.2356 - val_acc: 0.9827\n",
      "Epoch 120/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6614e-10 - acc: 1.0000 - val_loss: 0.2359 - val_acc: 0.9827\n",
      "Epoch 121/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.6864e-10 - acc: 1.0000 - val_loss: 0.2363 - val_acc: 0.9827\n",
      "Epoch 122/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6707e-10 - acc: 1.0000 - val_loss: 0.2362 - val_acc: 0.9827\n",
      "Epoch 123/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6630e-10 - acc: 1.0000 - val_loss: 0.2370 - val_acc: 0.9826\n",
      "Epoch 124/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6869e-10 - acc: 1.0000 - val_loss: 0.2374 - val_acc: 0.9826\n",
      "Epoch 125/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6786e-10 - acc: 1.0000 - val_loss: 0.2376 - val_acc: 0.9826\n",
      "Epoch 126/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6882e-10 - acc: 1.0000 - val_loss: 0.2384 - val_acc: 0.9826\n",
      "Epoch 127/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.7099e-10 - acc: 1.0000 - val_loss: 0.2389 - val_acc: 0.9826\n",
      "Epoch 128/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6935e-10 - acc: 1.0000 - val_loss: 0.2387 - val_acc: 0.9826\n",
      "Epoch 129/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6658e-10 - acc: 1.0000 - val_loss: 0.2390 - val_acc: 0.9826\n",
      "Epoch 130/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6837e-10 - acc: 1.0000 - val_loss: 0.2390 - val_acc: 0.9826\n",
      "Epoch 131/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6724e-10 - acc: 1.0000 - val_loss: 0.2397 - val_acc: 0.9826\n",
      "Epoch 132/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6708e-10 - acc: 1.0000 - val_loss: 0.2402 - val_acc: 0.9826\n",
      "Epoch 133/200\n",
      "31249/31249 [==============================] - 2s 62us/sample - loss: 1.6807e-10 - acc: 1.0000 - val_loss: 0.2401 - val_acc: 0.9826\n",
      "Epoch 134/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.6695e-10 - acc: 1.0000 - val_loss: 0.2404 - val_acc: 0.9826\n",
      "Epoch 135/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6572e-10 - acc: 1.0000 - val_loss: 0.2408 - val_acc: 0.9826\n",
      "Epoch 136/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.6747e-10 - acc: 1.0000 - val_loss: 0.2410 - val_acc: 0.9826\n",
      "Epoch 137/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6757e-10 - acc: 1.0000 - val_loss: 0.2414 - val_acc: 0.9825\n",
      "Epoch 138/200\n",
      "31249/31249 [==============================] - 2s 57us/sample - loss: 1.6966e-10 - acc: 1.0000 - val_loss: 0.2419 - val_acc: 0.9825\n",
      "Epoch 139/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6760e-10 - acc: 1.0000 - val_loss: 0.2420 - val_acc: 0.9825\n",
      "Epoch 140/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6804e-10 - acc: 1.0000 - val_loss: 0.2419 - val_acc: 0.9825\n",
      "Epoch 141/200\n",
      "31249/31249 [==============================] - 2s 63us/sample - loss: 1.6488e-10 - acc: 1.0000 - val_loss: 0.2422 - val_acc: 0.9825\n",
      "Epoch 142/200\n",
      "31249/31249 [==============================] - 2s 65us/sample - loss: 1.6718e-10 - acc: 1.0000 - val_loss: 0.2423 - val_acc: 0.9825\n",
      "Epoch 143/200\n",
      "31249/31249 [==============================] - 2s 64us/sample - loss: 1.6697e-10 - acc: 1.0000 - val_loss: 0.2427 - val_acc: 0.9825\n",
      "Epoch 144/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6248e-10 - acc: 1.0000 - val_loss: 0.2426 - val_acc: 0.9825\n",
      "Epoch 145/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6557e-10 - acc: 1.0000 - val_loss: 0.2435 - val_acc: 0.9824\n",
      "Epoch 146/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6670e-10 - acc: 1.0000 - val_loss: 0.2435 - val_acc: 0.9825\n",
      "Epoch 147/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6481e-10 - acc: 1.0000 - val_loss: 0.2432 - val_acc: 0.9825\n",
      "Epoch 148/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6412e-10 - acc: 1.0000 - val_loss: 0.2439 - val_acc: 0.9824\n",
      "Epoch 149/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6747e-10 - acc: 1.0000 - val_loss: 0.2437 - val_acc: 0.9825\n",
      "Epoch 150/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6498e-10 - acc: 1.0000 - val_loss: 0.2445 - val_acc: 0.9824\n",
      "Epoch 151/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6741e-10 - acc: 1.0000 - val_loss: 0.2441 - val_acc: 0.9824\n",
      "Epoch 152/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.6533e-10 - acc: 1.0000 - val_loss: 0.2449 - val_acc: 0.9824\n",
      "Epoch 153/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.6923e-10 - acc: 1.0000 - val_loss: 0.2450 - val_acc: 0.9824\n",
      "Epoch 154/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6623e-10 - acc: 1.0000 - val_loss: 0.2451 - val_acc: 0.9824\n",
      "Epoch 155/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6715e-10 - acc: 1.0000 - val_loss: 0.2451 - val_acc: 0.9824\n",
      "Epoch 156/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6657e-10 - acc: 1.0000 - val_loss: 0.2453 - val_acc: 0.9824\n",
      "Epoch 157/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6775e-10 - acc: 1.0000 - val_loss: 0.2460 - val_acc: 0.9824\n",
      "Epoch 158/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6648e-10 - acc: 1.0000 - val_loss: 0.2461 - val_acc: 0.9824\n",
      "Epoch 159/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6834e-10 - acc: 1.0000 - val_loss: 0.2460 - val_acc: 0.9824\n",
      "Epoch 160/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6710e-10 - acc: 1.0000 - val_loss: 0.2462 - val_acc: 0.9824\n",
      "Epoch 161/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6561e-10 - acc: 1.0000 - val_loss: 0.2463 - val_acc: 0.9824\n",
      "Epoch 162/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6718e-10 - acc: 1.0000 - val_loss: 0.2468 - val_acc: 0.9823\n",
      "Epoch 163/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6934e-10 - acc: 1.0000 - val_loss: 0.2471 - val_acc: 0.9823\n",
      "Epoch 164/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6853e-10 - acc: 1.0000 - val_loss: 0.2468 - val_acc: 0.9824\n",
      "Epoch 165/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6613e-10 - acc: 1.0000 - val_loss: 0.2473 - val_acc: 0.9823\n",
      "Epoch 166/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6824e-10 - acc: 1.0000 - val_loss: 0.2471 - val_acc: 0.9824\n",
      "Epoch 167/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6701e-10 - acc: 1.0000 - val_loss: 0.2474 - val_acc: 0.9823\n",
      "Epoch 168/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6655e-10 - acc: 1.0000 - val_loss: 0.2478 - val_acc: 0.9823\n",
      "Epoch 169/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6832e-10 - acc: 1.0000 - val_loss: 0.2475 - val_acc: 0.9823\n",
      "Epoch 170/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6584e-10 - acc: 1.0000 - val_loss: 0.2475 - val_acc: 0.9823\n",
      "Epoch 171/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6556e-10 - acc: 1.0000 - val_loss: 0.2481 - val_acc: 0.9823\n",
      "Epoch 172/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6730e-10 - acc: 1.0000 - val_loss: 0.2479 - val_acc: 0.9823\n",
      "Epoch 173/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6699e-10 - acc: 1.0000 - val_loss: 0.2486 - val_acc: 0.9823\n",
      "Epoch 174/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6989e-10 - acc: 1.0000 - val_loss: 0.2487 - val_acc: 0.9823\n",
      "Epoch 175/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6840e-10 - acc: 1.0000 - val_loss: 0.2486 - val_acc: 0.9823\n",
      "Epoch 176/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6753e-10 - acc: 1.0000 - val_loss: 0.2491 - val_acc: 0.9823\n",
      "Epoch 177/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6894e-10 - acc: 1.0000 - val_loss: 0.2484 - val_acc: 0.9823\n",
      "Epoch 178/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6314e-10 - acc: 1.0000 - val_loss: 0.2489 - val_acc: 0.9823\n",
      "Epoch 179/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6492e-10 - acc: 1.0000 - val_loss: 0.2490 - val_acc: 0.9823\n",
      "Epoch 180/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6442e-10 - acc: 1.0000 - val_loss: 0.2492 - val_acc: 0.9823\n",
      "Epoch 181/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.6654e-10 - acc: 1.0000 - val_loss: 0.2498 - val_acc: 0.9823\n",
      "Epoch 182/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6740e-10 - acc: 1.0000 - val_loss: 0.2498 - val_acc: 0.9823\n",
      "Epoch 183/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.6743e-10 - acc: 1.0000 - val_loss: 0.2498 - val_acc: 0.9823\n",
      "Epoch 184/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6657e-10 - acc: 1.0000 - val_loss: 0.2501 - val_acc: 0.9823\n",
      "Epoch 185/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6969e-10 - acc: 1.0000 - val_loss: 0.2504 - val_acc: 0.9823\n",
      "Epoch 186/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6767e-10 - acc: 1.0000 - val_loss: 0.2503 - val_acc: 0.9823\n",
      "Epoch 187/200\n",
      "31249/31249 [==============================] - 2s 61us/sample - loss: 1.6781e-10 - acc: 1.0000 - val_loss: 0.2502 - val_acc: 0.9823\n",
      "Epoch 188/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6736e-10 - acc: 1.0000 - val_loss: 0.2508 - val_acc: 0.9822\n",
      "Epoch 189/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6877e-10 - acc: 1.0000 - val_loss: 0.2504 - val_acc: 0.9823\n",
      "Epoch 190/200\n",
      "31249/31249 [==============================] - 2s 62us/sample - loss: 1.6667e-10 - acc: 1.0000 - val_loss: 0.2509 - val_acc: 0.9822\n",
      "Epoch 191/200\n",
      "31249/31249 [==============================] - 2s 63us/sample - loss: 1.6712e-10 - acc: 1.0000 - val_loss: 0.2508 - val_acc: 0.9823\n",
      "Epoch 192/200\n",
      "31249/31249 [==============================] - 2s 66us/sample - loss: 1.6780e-10 - acc: 1.0000 - val_loss: 0.2513 - val_acc: 0.9822\n",
      "Epoch 193/200\n",
      "31249/31249 [==============================] - 2s 64us/sample - loss: 1.6656e-10 - acc: 1.0000 - val_loss: 0.2510 - val_acc: 0.9823\n",
      "Epoch 194/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6555e-10 - acc: 1.0000 - val_loss: 0.2511 - val_acc: 0.9822\n",
      "Epoch 195/200\n",
      "31249/31249 [==============================] - 2s 60us/sample - loss: 1.6767e-10 - acc: 1.0000 - val_loss: 0.2516 - val_acc: 0.9822\n",
      "Epoch 196/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6748e-10 - acc: 1.0000 - val_loss: 0.2516 - val_acc: 0.9822\n",
      "Epoch 197/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6562e-10 - acc: 1.0000 - val_loss: 0.2516 - val_acc: 0.9822\n",
      "Epoch 198/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6693e-10 - acc: 1.0000 - val_loss: 0.2518 - val_acc: 0.9822\n",
      "Epoch 199/200\n",
      "31249/31249 [==============================] - 2s 59us/sample - loss: 1.6576e-10 - acc: 1.0000 - val_loss: 0.2520 - val_acc: 0.9822\n",
      "Epoch 200/200\n",
      "31249/31249 [==============================] - 2s 58us/sample - loss: 1.6815e-10 - acc: 1.0000 - val_loss: 0.2521 - val_acc: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f709c866b70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=100, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebf1d55a-cbfc-4b01-967a-6f1d00ba5eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74169 8173\n",
      "0 36148\n",
      "False negative rate:  0.09925675839790143\n",
      "Error rate:  0.06897628491855853\n",
      "Precision:  1.0\n",
      "Recall:  0.9007432416020986\n",
      "F1 score:  0.9477800282408265\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).flatten().astype(int)\n",
    "evaluate(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Tensorflow1.x] *",
   "language": "python",
   "name": "conda-env-Tensorflow1.x-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
